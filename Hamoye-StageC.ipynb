{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAMOYE STAGE C\n",
    " LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing neccesary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv(\"Data_for_UCI_named.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  unstable  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop stab column from the dataset\n",
    "dz=df.drop(columns=\"stab\")\n",
    "dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more preprocessing\n",
    "X = dz.drop(columns='stabf')\n",
    "y = dz['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5092\n",
       "stable      2908\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing StandardScaler\n",
    "The idea behind StandardScaler is that it will transform your data such \n",
    "that its distribution will have a mean value 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using StandardScaler on split data.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler_train=scaler.fit_transform(x_train)\n",
    "scaler_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier\n",
    "The random forest is a classification algorithm consisting of many decisions trees.\n",
    "It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by\n",
    "committee is more accurate than that of any individual tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state=1)\n",
    "classifier.fit(scaler_train, y_train)\n",
    "y_pred=classifier.predict(scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 625   87]\n",
      " [  55 1233]]\n",
      "0.929000\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of random forest classifier model\n",
    "from sklearn.metrics import  confusion_matrix, accuracy_score\n",
    "\n",
    "print((confusion_matrix(y_test,y_pred)))\n",
    "print(\"{:.6f}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBCLASSIFIER\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm\n",
    "that uses a gradient boosting framework. In prediction problems involving\n",
    "unstructured data (images, text, etc.) artificial neural networks tend to\n",
    "outperform all other algorithms or frameworks. However, when it comes to\n",
    "small-to-medium structured/tabular data, decision tree based algorithms are\n",
    "considered best-in-class right now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using xgboost classifier\n",
    "from xgboost import XGBClassifier\n",
    "extreme1 = XGBClassifier(random_state=1,learning_rate=0.1,max_depth=3)\n",
    "extreme1.fit(scaler_train, y_train)\n",
    "extreme1_pred = extreme1.predict(scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 625   87]\n",
      " [  55 1233]]\n",
      "0.919500\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of xgboost classifier model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print((confusion_matrix(y_test,y_pred)))\n",
    "print(\"{:.6f}\".format(accuracy_score(y_test,extreme1_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGHTGBMCLASSIFIER\n",
    "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithm, used for ranking, classification and many other machine learning tasks.Also, it is surprisingly very fast, hence the word â€˜Lightâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " #installing lightgbm classifier\n",
    "    pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using lightgbm classifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "lg = lgb.LGBMClassifier(random_state=1)\n",
    "lg.fit(scaler_train, y_train)\n",
    "lg_pred=lg.predict(scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of lightgbm classifier model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,lg_pred))\n",
    "print((accuracy_score(y_test,lg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRATREECLASSIFIER\n",
    "The Extra Trees algorithm works by creating a large number of unpruned decision trees from the training dataset. \n",
    "Predictions are made by averaging the prediction of the decision trees\n",
    "in the case of regression or using majority voting in the case of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra tree classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier(random_state=1)\n",
    "tree.fit(scaler_train, y_train)\n",
    "tree_pred = tree.predict(scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 606  106]\n",
      " [  38 1250]]\n",
      "0.928\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of exta tree classifier model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,tree_pred))\n",
    "print(accuracy_score(y_test,tree_pred))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree tuning using hyper parameters setting\n",
    "Now to improve the Extra Trees Classifier, you will use the following parameters\n",
    "\n",
    "Number of estimators\n",
    "Minimum number of samples,\n",
    "Minimum number of samples for leaf node and\n",
    "The number of features to consider when looking for the best split\n",
    "\n",
    "For the hyperparameter grid needed to run a Randomized Cross Validation Search (RandomizedSearchCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = RandomizedSearchCV(tree, hyperparameter_grid, n_iter=10,cv=5,scoring='accuracy', n_jobs=-1,verbose =1, random_state= 1)\n",
    "search = clf.fit(scaler_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1000, 2, 8, None])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for the best parameter for the model\n",
    "search.best_params_.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with this parameter to test the model's performance\n",
    "tree_param = ExtraTreesClassifier(n_estimators=1000, min_samples_split=2, min_samples_leaf=8, max_features=None,random_state=1)\n",
    "tree_param.fit(scaler_train, y_train)\n",
    "tree_param_pred = tree_param.predict(scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.92      0.87      0.89       712\n",
      "    unstable       0.93      0.96      0.94      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.91      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n",
      "[[ 619   93]\n",
      " [  53 1235]]\n",
      "0.9270\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of optimized model\n",
    "from sklearn.metrics import  confusion_matrix, accuracy_score\n",
    "\n",
    "print((confusion_matrix(y_test,tree_param_pred)))\n",
    "print(\"{:.4f}\".format(accuracy_score(y_test,tree_param_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Feature Selection\n",
    "Feature Selection is the process where you automatically or manually select those features which contribute most to your \n",
    "prediction variable or output in which you are interested in.\n",
    "Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13723975 0.1405075  0.13468029 0.13541676 0.00368342 0.00533686\n",
      " 0.00542927 0.00496249 0.10256244 0.10757765 0.11306268 0.10954089]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library to plot a graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#use inbuilt class feature_importances of tree based classifiers\n",
    "print(tree_param.feature_importances_)\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(tree_param.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(12).plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19346049046321526"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let: Precision =P Recall=R TruePositive=TP TrueNegative=TN FalsePositive=FP FalseNegative=FN\n",
    "TP=355;FP=1480;FN=45;\n",
    "P=(TP/(TP+FP))\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R=(TP/(TP+FN))\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3176733780760626"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score=(2*((P*R)/(P+R)))\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate recall,false positve rate and cost \n",
    "#Recall=(TP/(TP+FN))\n",
    "#False Positive Rate(FPR)=(FP/(FP+TN))\n",
    "#Cost=(5*(FP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
